{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch Data\n",
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "DOWNLOAD_ROOT = \"https://raw.githubsercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\",\"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT +\"datasets/housing/housing.tgz\"\n",
    "\n",
    "#Fetch data that is download and extract data\n",
    "def fetch_housing_data(housing_url =HOUSING_URL,housing_path = HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "        tgz_path = os.path.join(housing_path,\"housing.tgz\")\n",
    "        urllib.request.urlretrieve(housing_url,tgz_path)\n",
    "        housing_tgz = tarfile.open(tgz_path)\n",
    "        housing_tgz.extractall(path=housing_path)\n",
    "        housing_tgz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dataset\n",
    "#This function returns a Pandas DataFrame object containing all the data.\n",
    "import pandas as pd\n",
    "def load_housing_data(housing_path =HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path,\"hoising.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "housing = load_housing_data()\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To plot a histogram\n",
    "%matplotlib\tinline\n",
    "import matplotlib.pyplot as plt\n",
    "housing.hist(bins=50,figsize=(20,15)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create\ta\tTest\tSet  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def\tsplit_train_test(data,\ttest_ratio):\n",
    "    shuffled_indices=np.random.permutation(len(data))\n",
    "    test_set_size=int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return\tdata.iloc[train_indices],\tdata.iloc[test_indices]\n",
    "\n",
    "\n",
    "train_set, test_set = split_train_test(housing,\t0.2)\n",
    "print(len(train_set),\"train +\", len(test_set),\"test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a copy so you can play with it without harming the training set:\n",
    "housing =strat_train_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding color to scatter plot using various parameter\n",
    "housing.plot(kind=\"scatter\",\tx=\"longitude\",\ty=\"latitude\",\talpha=0.4,\n",
    "             s=housing[\"population\"]/100,\tlabel=\"population\",\tfigsize=(10,7),\n",
    "             c=\"median_house_value\",\tcmap=plt.get_cmap(\"jet\"),\tcolorbar=True,)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so that it always generates the\tsame shuffled indices.\n",
    "import\thashlib\n",
    "def test_set_check(identifier,\ttest_ratio, hash):\n",
    "    return hash(np.int64(identifier)).digest()[-1] < 256*test_ratio\n",
    "def split_train_test_by_id(data,test_ratio,\tid_column, hash=hashlib.md5):\n",
    "    ids = data[id_column]\n",
    "    in_test_set = ids.apply(lambda id_:test_set_check(id_, test_ratio, hash))\n",
    "    return data.loc[~in_test_set],data.loc[in_test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To split the dataset\n",
    "from sklearn.model_selection\timport train_test_split\n",
    "train_set,\ttest_set = train_test_split(housing, test_size=0.2,\trandom_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find correlation \n",
    "#Using pearson's correlational\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another way to check for correlation between attributes is to use Pandasâ€™ scatter_matrix function, which plots\tevery numerical attribute against every other numerical attribute\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n",
    "              \"housing_median_age\"]\n",
    "scatter_matrix(housing[attributes], figsize=(12,8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
